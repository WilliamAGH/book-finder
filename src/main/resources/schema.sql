-- Enable required extensions
create extension if not exists pg_trgm;

-- Books - canonical record
-- This is our single source of truth for book data, merged from all providers
create table if not exists books (
  id uuid primary key, -- UUIDv7 generated by our application (NOT provider IDs)
  title text not null, -- JSON: volumeInfo.title
  subtitle text, -- JSON: volumeInfo.subtitle
  description text, -- JSON: volumeInfo.description (HTML from providers)
  isbn10 text, -- Canonical ISBN-10 (best available from all sources)
  isbn13 text, -- Canonical ISBN-13 (best available from all sources)
  published_date date, -- JSON: volumeInfo.publishedDate (parsed from various formats)
  language text, -- JSON: volumeInfo.language (ISO 639-1 code like 'en')
  publisher text, -- JSON: volumeInfo.publisher
  page_count integer, -- JSON: volumeInfo.pageCount or volumeInfo.printedPageCount
  edition_number integer, -- Normalized edition number (highest governs primary selection)
  edition_group_key text, -- Normalized work key (title + primary author) for linking sibling editions
  slug text unique, -- SEO-friendly URL slug (e.g., 'harry-potter-philosophers-stone-j-k-rowling')
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now(),
  -- Generated search vector for full-text search
  search_vector tsvector generated always as (
    setweight(to_tsvector('english', coalesce(title, '')), 'A') ||
    setweight(to_tsvector('english', coalesce(subtitle, '')), 'B') ||
    setweight(to_tsvector('english', coalesce(publisher, '')), 'C') ||
    setweight(to_tsvector('english', coalesce(description, '')), 'D')
  ) stored
);

create index if not exists idx_books_isbn13 on books(isbn13) where isbn13 is not null;
create index if not exists idx_books_isbn10 on books(isbn10) where isbn10 is not null;
create unique index if not exists uq_books_isbn13 on books(isbn13) where isbn13 is not null;
create unique index if not exists uq_books_isbn10 on books(isbn10) where isbn10 is not null;
create index if not exists idx_books_edition_group_key on books(edition_group_key) where edition_group_key is not null;
create index if not exists idx_books_slug on books(slug); -- Always index slug for URL lookups
-- Removed idx_books_s3_image_path - images are now tracked in book_image_links table
create index if not exists idx_books_created_at on books(created_at desc);
create index if not exists idx_books_updated_at on books(updated_at desc);
create index if not exists idx_books_search_vector on books using gin (search_vector);

-- Table and column comments for books
comment on table books is 'Canonical book records - single source of truth merged from all providers';
comment on column books.id is 'UUIDv7 generated by our application (NOT provider IDs)';
comment on column books.title is 'Book title from volumeInfo.title';
comment on column books.subtitle is 'Book subtitle from volumeInfo.subtitle';
comment on column books.description is 'Book description from volumeInfo.description (HTML from providers)';
comment on column books.isbn10 is 'Canonical ISBN-10 (best available from all sources)';
comment on column books.isbn13 is 'Canonical ISBN-13 (best available from all sources)';
comment on column books.published_date is 'Publication date from volumeInfo.publishedDate';
comment on column books.language is 'Language code (ISO 639-1) from volumeInfo.language';
comment on column books.publisher is 'Publisher name from volumeInfo.publisher';
comment on column books.page_count is 'Page count from volumeInfo.pageCount or printedPageCount';
comment on column books.edition_number is 'Edition number (if known) used to determine primary release for sibling editions';
comment on column books.edition_group_key is 'Normalized work key (title + primary author) for grouping sibling editions';
comment on column books.slug is 'SEO-friendly URL slug generated once at creation, remains stable even if title/authors change';

-- External IDs mapping for many-to-one association to canonical books
-- This includes Google Books ID, OpenLibrary ID, etc. with provider-specific metadata
-- IMPORTANT: One book can have multiple external IDs (Google, Amazon, OpenLibrary, etc.)
create table if not exists book_external_ids (
  id text primary key, -- NanoID (10 chars via IdGenerator.generate())
  book_id uuid not null references books(id) on delete cascade,
  source text not null, -- 'GOOGLE_BOOKS', 'OPEN_LIBRARY', 'AMAZON', etc.
  external_id text not null, -- Provider's ID (JSON: id for Google Books)
  -- Industry identifiers from this provider
  provider_isbn10 text, -- JSON: volumeInfo.industryIdentifiers[type=ISBN_10].identifier
  provider_isbn13 text, -- JSON: volumeInfo.industryIdentifiers[type=ISBN_13].identifier
  provider_oclc text, -- OCLC number if provided
  provider_lccn text, -- Library of Congress Control Number if provided
  provider_asin text, -- Amazon Standard Identification Number
  -- Provider-specific metadata
  info_link text, -- JSON: volumeInfo.infoLink (Google Books info page)
  preview_link text, -- JSON: volumeInfo.previewLink
  web_reader_link text, -- JSON: accessInfo.webReaderLink
  purchase_link text, -- Link to purchase page if available
  canonical_volume_link text, -- JSON: volumeInfo.canonicalVolumeLink
  average_rating numeric, -- JSON: volumeInfo.averageRating (provider's rating)
  ratings_count integer, -- JSON: volumeInfo.ratingsCount
  review_count integer, -- Number of reviews on this platform
  -- Provider-specific availability
  is_ebook boolean, -- JSON: saleInfo.isEbook
  pdf_available boolean, -- JSON: accessInfo.pdf.isAvailable
  epub_available boolean, -- JSON: accessInfo.epub.isAvailable
  embeddable boolean, -- JSON: accessInfo.embeddable
  public_domain boolean, -- JSON: accessInfo.publicDomain
  viewability text, -- JSON: accessInfo.viewability ('FULL', 'PARTIAL', 'NO_PAGES', 'ALL_PAGES')
  text_readable boolean, -- JSON: volumeInfo.readingModes.text
  image_readable boolean, -- JSON: volumeInfo.readingModes.image
  -- Content metadata
  print_type text, -- JSON: volumeInfo.printType ('BOOK', 'MAGAZINE')
  maturity_rating text, -- JSON: volumeInfo.maturityRating ('NOT_MATURE', 'MATURE')
  content_version text, -- JSON: volumeInfo.contentVersion
  text_to_speech_permission text, -- JSON: accessInfo.textToSpeechPermission
  -- Sale info
  saleability text, -- JSON: saleInfo.saleability ('FOR_SALE', 'NOT_FOR_SALE', 'FREE')
  country_code text, -- JSON: saleInfo.country or accessInfo.country
  is_ebook_for_sale boolean, -- Derived from saleInfo
  -- Pricing info if available
  list_price numeric,
  retail_price numeric,
  currency_code text,
  -- Metadata
  last_updated timestamptz,
  created_at timestamptz not null default now(),
  unique(source, external_id)
);

create index if not exists idx_book_external_ids_book_id on book_external_ids(book_id);
create index if not exists idx_book_external_ids_external_id on book_external_ids(external_id);
create index if not exists idx_book_external_ids_source_id on book_external_ids(source, external_id);
create unique index if not exists uq_book_external_ids_provider_isbn13
  on book_external_ids(source, provider_isbn13) where provider_isbn13 is not null;
create unique index if not exists uq_book_external_ids_provider_isbn10
  on book_external_ids(source, provider_isbn10) where provider_isbn10 is not null;
create index if not exists idx_book_external_ids_isbn13 on book_external_ids(provider_isbn13) where provider_isbn13 is not null;
create index if not exists idx_book_external_ids_isbn10 on book_external_ids(provider_isbn10) where provider_isbn10 is not null;
create index if not exists idx_book_external_ids_asin on book_external_ids(provider_asin) where provider_asin is not null;

-- Table and column comments for book_external_ids
comment on table book_external_ids is 'External provider IDs and metadata for books (Google Books, Amazon, OpenLibrary, etc.)';
comment on column book_external_ids.external_id is 'Provider-specific ID (e.g., Google Books ID from JSON id field)';
comment on column book_external_ids.source is 'Provider name: GOOGLE_BOOKS, OPEN_LIBRARY, AMAZON, etc.';
comment on column book_external_ids.provider_isbn10 is 'ISBN-10 from volumeInfo.industryIdentifiers[type=ISBN_10]';
comment on column book_external_ids.provider_isbn13 is 'ISBN-13 from volumeInfo.industryIdentifiers[type=ISBN_13]';
comment on column book_external_ids.info_link is 'Provider info page from volumeInfo.infoLink';
comment on column book_external_ids.preview_link is 'Preview page from volumeInfo.previewLink';
comment on column book_external_ids.web_reader_link is 'Web reader from accessInfo.webReaderLink';
comment on column book_external_ids.canonical_volume_link is 'Canonical link from volumeInfo.canonicalVolumeLink';
comment on column book_external_ids.average_rating is 'Provider rating from volumeInfo.averageRating';
comment on column book_external_ids.ratings_count is 'Rating count from volumeInfo.ratingsCount';
comment on column book_external_ids.viewability is 'Access level from accessInfo.viewability (FULL, PARTIAL, NO_PAGES)';
comment on column book_external_ids.print_type is 'Content type from volumeInfo.printType (BOOK, MAGAZINE)';
comment on column book_external_ids.maturity_rating is 'Content rating from volumeInfo.maturityRating';
comment on column book_external_ids.saleability is 'Sale status from saleInfo.saleability';

-- Edition relationships for DRY linking of sibling canonical books
create table if not exists book_editions (
  id text primary key, -- NanoID (12 chars via IdGenerator.generateLong())
  book_id uuid not null references books(id) on delete cascade,
  related_book_id uuid not null references books(id) on delete cascade,
  link_source text not null, -- Origin of the link (S3_MIGRATION, INGESTION, MANUAL)
  relationship_type text default 'ALTERNATE_EDITION', -- How the related book participates (ALTERNATE_EDITION, TRANSLATION, AUDIOBOOK, etc.)
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now(),
  check (book_id <> related_book_id)
);

create unique index if not exists uq_book_editions_pair on book_editions(book_id, related_book_id);
create index if not exists idx_book_editions_book_id on book_editions(book_id);
create index if not exists idx_book_editions_related_book_id on book_editions(related_book_id);

comment on table book_editions is 'Links canonical books that represent the same work; rows only exist when multiple sibling editions are present.';
comment on column book_editions.book_id is 'Primary (highest edition number) canonical book in an edition set.';
comment on column book_editions.related_book_id is 'Sibling canonical book linked to the primary record.';
comment on column book_editions.link_source is 'Process that established this link (migration, ingestion, manual curation, etc.).';
comment on column book_editions.relationship_type is 'Descriptor of the relationship between linked books (ALTERNATE_EDITION, AUDIOBOOK, etc.).';

-- View exposing edition chains in both directions for efficient UI traversal
create or replace view book_editions_chain as
select
  be.book_id,
  be.related_book_id,
  be.id as edition_link_id,
  be.relationship_type,
  be.link_source,
  be.created_at,
  be.updated_at
from book_editions be
union all
select
  be.related_book_id as book_id,
  be.book_id as related_book_id,
  be.id as edition_link_id,
  be.relationship_type,
  be.link_source,
  be.created_at,
  be.updated_at
from book_editions be;

comment on view book_editions_chain is 'Pre-resolved edition relationships for chaining canonical books in both directions.';

-- Tags / qualifiers --------------------------------------------------------

create table if not exists book_tags (
  id text primary key, -- NanoID (10 chars)
  key text not null, -- canonical tag key (e.g., 'nyt_bestseller')
  display_name text, -- human friendly label (e.g., 'NYT Bestseller')
  tag_type text not null default 'QUALIFIER', -- QUALIFIER, PROVIDER_TAG, USER_TAG, etc.
  description text,
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now(),
  unique (key)
);

create table if not exists book_tag_equivalents (
  id text primary key, -- NanoID (10 chars)
  canonical_tag_id text not null references book_tags(id) on delete cascade,
  equivalent_tag_id text not null references book_tags(id) on delete cascade,
  created_at timestamptz not null default now(),
  unique (canonical_tag_id, equivalent_tag_id)
);

create table if not exists book_tag_assignments (
  id text primary key, -- NanoID (12 chars)
  book_id uuid not null references books(id) on delete cascade,
  tag_id text not null references book_tags(id) on delete cascade,
  source text not null, -- 'SEARCH_QUERY', 'PROVIDER', 'CURATION', etc.
  confidence numeric, -- optional 0..1 confidence score
  metadata jsonb, -- optional extra data (e.g., original phrase, provider payload snippet)
  created_at timestamptz not null default now(),
  unique (book_id, tag_id, source)
);

create index if not exists idx_book_tag_equivalents_canonical on book_tag_equivalents(canonical_tag_id);
create index if not exists idx_book_tag_equivalents_equivalent on book_tag_equivalents(equivalent_tag_id);
create index if not exists idx_book_tag_assignments_book_id on book_tag_assignments(book_id);
create index if not exists idx_book_tag_assignments_tag_id on book_tag_assignments(tag_id);

comment on table book_tags is 'Canonical tags/qualifiers applied to books (e.g., NYT bestseller, award winner).';
comment on column book_tags.key is 'Stable key used across services (snake_case).';
comment on column book_tags.tag_type is 'Tag classification: QUALIFIER, PROVIDER_TAG, USER_TAG, etc.';

comment on table book_tag_equivalents is 'Pairs of tags that should be treated as equivalents/aliases.';
comment on column book_tag_equivalents.canonical_tag_id is 'Primary tag in an equivalence relationship.';
comment on column book_tag_equivalents.equivalent_tag_id is 'Alias tag that resolves to the canonical tag.';

comment on table book_tag_assignments is 'Assignments linking canonical books to tags with source + optional metadata.';
comment on column book_tag_assignments.source is 'Origin of the tag assignment (SEARCH_QUERY, PROVIDER, CURATION, etc).';
comment on column book_tag_assignments.metadata is 'Additional context, e.g., original query text or provider payload snippet.';

-- Authors table for storing unique author names
create table if not exists authors (
  id text primary key, -- NanoID (10 chars via IdGenerator.generate())
  name text not null unique, -- JSON: volumeInfo.authors[] array elements
  normalized_name text, -- For deduplication: lowercase, no accents, etc.
  birth_date date, -- From external sources when available
  death_date date, -- From external sources when available
  biography text, -- Author bio from various sources
  nationality text, -- Country/nationality when known
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now(),
  -- Generated search vector for author name search
  search_vector tsvector generated always as (
    to_tsvector('english', coalesce(name, ''))
  ) stored
);

create index if not exists idx_authors_name on authors(name);
create index if not exists idx_authors_normalized_name on authors(normalized_name);
create index if not exists idx_authors_search_vector on authors using gin (search_vector);

-- Table comments for authors
comment on table authors is 'Canonical author records deduplicated across all sources';
comment on column authors.name is 'Author name from volumeInfo.authors[] array';
comment on column authors.normalized_name is 'Lowercase, no accents version for deduplication';

-- External IDs and metadata for authors from various providers
create table if not exists author_external_ids (
  id text primary key, -- NanoID (10 chars via IdGenerator.generate())
  author_id text not null references authors(id) on delete cascade,
  source text not null, -- 'GOOGLE_BOOKS', 'OPEN_LIBRARY', 'GOODREADS', 'VIAF', 'ISNI', 'ORCID', 'WIKIDATA', etc.
  external_id text not null,
  -- Provider-specific metadata
  profile_url text,
  image_url text,
  follower_count integer,
  book_count integer,
  average_rating numeric,
  ratings_count integer,
  -- Additional metadata
  verified boolean,
  last_updated timestamptz,
  created_at timestamptz not null default now(),
  unique(source, external_id)
);

create index if not exists idx_author_external_ids_author_id on author_external_ids(author_id);
create index if not exists idx_author_external_ids_external_id on author_external_ids(external_id);
create index if not exists idx_author_external_ids_source_id on author_external_ids(source, external_id);

-- Join table linking books to authors (many-to-many)
create table if not exists book_authors_join (
  id text primary key, -- NanoID (12 chars via IdGenerator.generateLong() - high volume)
  book_id uuid not null references books(id) on delete cascade,
  author_id text not null references authors(id) on delete cascade,
  position integer not null default 0, -- Order of author as it appears in the book
  created_at timestamptz not null default now(),
  unique(book_id, author_id)
);

create index if not exists idx_book_authors_book_id on book_authors_join(book_id);
create index if not exists idx_book_authors_author_id on book_authors_join(author_id);
create index if not exists idx_book_authors_position on book_authors_join(book_id, position);


-- Store the full raw JSON response for debugging/reprocessing
-- Also serves as contributing sources tracking (presence of a record = contributed data)
create table if not exists book_raw_data (
  id text primary key, -- NanoID (10 chars)
  book_id uuid not null references books(id) on delete cascade,
  raw_json_response jsonb not null, -- Complete API response as JSONB
  source text not null, -- 'GOOGLE_BOOKS', 'OPEN_LIBRARY', etc.
  fetched_at timestamptz not null default now(), -- When we fetched this data
  contributed_at timestamptz not null default now(), -- When this source contributed to the book
  created_at timestamptz not null default now(),
  unique(book_id, source)
);

create index if not exists idx_book_raw_data_book_id on book_raw_data(book_id);
create index if not exists idx_book_raw_data_source on book_raw_data(source);

-- Table comments for book_raw_data
comment on table book_raw_data is 'Raw JSON responses from providers for debugging/reprocessing';
comment on column book_raw_data.raw_json_response is 'Complete API response as JSONB';
comment on column book_raw_data.source is 'Provider that supplied this data';
comment on column book_raw_data.contributed_at is 'When this source contributed to the book record';

-- Store dimensions separately (not all books have this)
create table if not exists book_dimensions (
  id text primary key, -- NanoID (8 chars via IdGenerator.generateShort())
  book_id uuid not null references books(id) on delete cascade,
  height_cm numeric, -- JSON: volumeInfo.dimensions.height (parsed from "23.00 cm")
  width_cm numeric, -- JSON: volumeInfo.dimensions.width (if available)
  thickness_cm numeric, -- JSON: volumeInfo.dimensions.thickness (if available)
  weight_grams numeric, -- From other sources if available
  created_at timestamptz not null default now(),
  unique(book_id)
);

create index if not exists idx_book_dimensions_book_id on book_dimensions(book_id);

-- Table comments for book_dimensions
comment on table book_dimensions is 'Physical dimensions of books when available';
comment on column book_dimensions.height_cm is 'Height parsed from volumeInfo.dimensions.height';

-- Store various image URLs from providers and map them to our S3 copies
create table if not exists book_image_links (
  id text primary key, -- NanoID (10 chars)
  book_id uuid not null references books(id) on delete cascade,
  image_type text not null, -- JSON keys: 'smallThumbnail', 'thumbnail', 'small', 'medium', 'large', 'extraLarge'
  url text not null, -- JSON: volumeInfo.imageLinks.{imageType} - full external URL
  source text, -- 'GOOGLE_BOOKS', etc. - which API provided this image
  created_at timestamptz not null default now(),
  unique(book_id, image_type)
);

create index if not exists idx_book_image_links_book_id on book_image_links(book_id);

-- Table comments for book_image_links
comment on table book_image_links is 'Maps external image URLs to our S3-persisted copies';
comment on column book_image_links.image_type is 'Image size: smallThumbnail, thumbnail, small, medium, large, extraLarge';
comment on column book_image_links.url is 'External URL from volumeInfo.imageLinks';


-- Unified collections table for categories, lists, and custom collections
-- Can represent: NYT bestseller lists, Google Books categories, custom user lists, etc.
create table if not exists book_collections (
  id                 text primary key, -- NanoID (8 chars for low volume)
  collection_type    text not null, -- 'CATEGORY', 'BESTSELLER_LIST', 'CUSTOM_LIST', 'TAG', etc.
  source             text not null, -- 'NYT', 'GOOGLE_BOOKS', 'USER', 'SYSTEM', etc.
  provider_list_id   text, -- External ID if from a provider
  provider_list_code text, -- External code/slug if from a provider
  display_name       text not null, -- JSON: volumeInfo.categories[] or list display name
  normalized_name    text, -- For deduplication and searching
  description        text, -- Description of the collection/category
  parent_collection_id text references book_collections(id) on delete set null, -- For hierarchical categories
  -- List-specific fields (null for categories)
  bestsellers_date   date,
  published_date     date,
  updated_frequency  text,
  -- Metadata
  is_public          boolean default true,
  is_active          boolean default true,
  sort_order         integer,
  raw_data_json      jsonb, -- Raw data from provider if applicable
  created_at         timestamptz not null default now(),
  updated_at         timestamptz not null default now()
);

create unique index if not exists uq_book_collections_source_code_date
  on book_collections (source, provider_list_code, published_date)
  where provider_list_code is not null and published_date is not null;

create index if not exists idx_book_collections_type on book_collections(collection_type);
create index if not exists idx_book_collections_name on book_collections(display_name);
create index if not exists idx_book_collections_normalized on book_collections(normalized_name);
create unique index if not exists uq_book_collections_category
  on book_collections (collection_type, source, normalized_name)
  where collection_type = 'CATEGORY' and normalized_name is not null;
create index if not exists idx_book_collections_parent on book_collections(parent_collection_id);
create index if not exists idx_book_collections_latest
  on book_collections (source, provider_list_code, published_date desc)
  where provider_list_code is not null;

-- Join table linking books to collections (categories, lists, etc.)
create table if not exists book_collections_join (
  id                text primary key, -- NanoID (12 chars via IdGenerator.generateLong() - high volume)
  collection_id     text not null references book_collections(id) on delete cascade,
  book_id           uuid not null references books(id) on delete cascade,
  -- Position/ranking in the collection (for ordered lists)
  position          integer, -- Rank in bestseller list or sort order
  -- List-specific metadata
  weeks_on_list     integer, -- For bestseller lists
  rank_last_week    integer, -- Previous rank for trending
  peak_position     integer, -- Best rank achieved
  -- Provider references if the book was added via external data
  provider_isbn13   text, -- ISBN from the list provider
  provider_isbn10   text, -- ISBN-10 from the list provider
  provider_book_ref text, -- Provider's reference/ID for this book
  -- Custom metadata (ratings, notes, etc.)
  user_rating       numeric, -- User's personal rating if custom list
  notes             text, -- User notes about why book is in this collection
  -- Raw data from provider if applicable
  raw_item_json     jsonb, -- Complete list item data from provider
  -- Timestamps
  added_at          timestamptz not null default now(),
  created_at        timestamptz not null default now(),
  updated_at        timestamptz not null default now(),
  unique (collection_id, book_id)
);

create unique index if not exists uq_book_collections_join_position
  on book_collections_join (collection_id, position)
  where position is not null;

create index if not exists idx_book_collections_join_collection on book_collections_join(collection_id);
create index if not exists idx_book_collections_join_book on book_collections_join(book_id);
create index if not exists idx_book_collections_join_added on book_collections_join(collection_id, added_at desc);

-- Table comments for book_collections
comment on table book_collections is 'Unified table for categories, bestseller lists, and custom collections';
comment on column book_collections.collection_type is 'Type: CATEGORY, BESTSELLER_LIST, CUSTOM_LIST, TAG';
comment on column book_collections.source is 'Origin: NYT, GOOGLE_BOOKS, USER, SYSTEM';
comment on column book_collections.display_name is 'Display name from volumeInfo.categories[] or list name';

-- Table comments for book_collections_join
comment on table book_collections_join is 'Many-to-many relationship between books and collections';
comment on column book_collections_join.position is 'Rank in bestseller list or sort order';
comment on column book_collections_join.weeks_on_list is 'Number of weeks on bestseller list';

-- ============================================================================
-- SEARCH FUNCTIONALITY
-- ============================================================================

-- Materialized view for optimized book search
-- Denormalizes books with authors for fast full-text and fuzzy search
create materialized view if not exists book_search_view as
select
  b.id as book_id,
  b.title,
  b.subtitle,
  b.slug,
  b.isbn13,
  b.isbn10,
  b.published_date,
  b.publisher,
  b.language,
  b.page_count,
  string_agg(a.name, ', ' order by ba.position) as authors,
  -- Combined search vector with weights:
  -- A: title, author names (highest priority)
  -- B: subtitle (high priority)
  -- C: publisher (medium priority)
  -- D: description (low priority)
  (
    setweight(to_tsvector('english', coalesce(b.title, '')), 'A') ||
    setweight(to_tsvector('english', coalesce(string_agg(a.name, ' ' order by ba.position), '')), 'A') ||
    setweight(to_tsvector('english', coalesce(b.subtitle, '')), 'B') ||
    setweight(to_tsvector('english', coalesce(b.publisher, '')), 'C') ||
    setweight(to_tsvector('english', coalesce(b.description, '')), 'D')
  ) as search_vector,
  -- Searchable text for trigram similarity (fuzzy matching)
  lower(
    coalesce(b.title, '') || ' ' ||
    coalesce(b.subtitle, '') || ' ' ||
    coalesce(string_agg(a.name, ' ' order by ba.position), '') || ' ' ||
    coalesce(b.publisher, '')
  ) as searchable_text
from books b
left join book_authors_join ba on b.id = ba.book_id
left join authors a on ba.author_id = a.id
group by b.id;

-- Indexes for the materialized view
create index if not exists idx_book_search_view_search_vector
  on book_search_view using gin (search_vector);

create index if not exists idx_book_search_view_searchable_text
  on book_search_view using gin (searchable_text gin_trgm_ops);

-- Unique index for concurrent refresh
create unique index if not exists idx_book_search_view_book_id
  on book_search_view (book_id);

-- Function to refresh the search view (call after bulk updates)
create or replace function refresh_book_search_view()
returns void as $$
begin
  refresh materialized view concurrently book_search_view;
end;
$$ language plpgsql;

-- Main search function combining multiple strategies
create or replace function search_books(
  search_query text,
  max_results integer default 20
)
returns table (
  book_id uuid,
  title text,
  subtitle text,
  authors text,
  isbn13 text,
  isbn10 text,
  published_date date,
  publisher text,
  relevance_score float,
  match_type text
) as $$
begin
  return query
  with
  -- Strategy 1: Exact title matches (highest priority)
  exact_matches as (
    select
      b.book_id,
      b.title,
      b.subtitle,
      b.authors,
      b.isbn13,
      b.isbn10,
      b.published_date,
      b.publisher,
      1.0::float as relevance_score,
      'exact_title'::text as match_type
    from book_search_view b
    where lower(b.title) = lower(search_query)
    limit 5
  ),
  -- Strategy 2: Full-text search with ranking
  fulltext_matches as (
    select
      b.book_id,
      b.title,
      b.subtitle,
      b.authors,
      b.isbn13,
      b.isbn10,
      b.published_date,
      b.publisher,
      ts_rank(b.search_vector, plainto_tsquery('english', search_query))::float as relevance_score,
      'fulltext'::text as match_type
    from book_search_view b
    where b.search_vector @@ plainto_tsquery('english', search_query)
      and b.book_id not in (select em.book_id from exact_matches em)
    order by relevance_score desc
    limit max_results
  ),
  -- Strategy 3: Fuzzy matches for typo tolerance
  fuzzy_matches as (
    select
      b.book_id,
      b.title,
      b.subtitle,
      b.authors,
      b.isbn13,
      b.isbn10,
      b.published_date,
      b.publisher,
      similarity(b.searchable_text, lower(search_query))::float * 0.8 as relevance_score,
      'fuzzy'::text as match_type
    from book_search_view b
    where b.searchable_text % lower(search_query)
      and b.book_id not in (
        select em.book_id from exact_matches em
        union select fm.book_id from fulltext_matches fm
      )
    order by relevance_score desc
    limit 10
  )
  -- Combine all results
  select * from exact_matches
  union all
  select * from fulltext_matches
  union all
  select * from fuzzy_matches
  order by relevance_score desc
  limit max_results;
end;
$$ language plpgsql;

-- ISBN search function for barcode scanning
create or replace function search_by_isbn(isbn_query text)
returns table (
  book_id uuid,
  title text,
  subtitle text,
  authors text,
  isbn13 text,
  isbn10 text,
  published_date date,
  publisher text
) as $$
declare
  clean_isbn text;
begin
  -- Remove any non-digit characters from ISBN
  clean_isbn := regexp_replace(isbn_query, '[^0-9]', '', 'g');

  return query
  select
    b.id as book_id,
    b.title,
    b.subtitle,
    string_agg(a.name, ', ' order by ba.position) as authors,
    b.isbn13,
    b.isbn10,
    b.published_date,
    b.publisher
  from books b
  left join book_authors_join ba on b.id = ba.book_id
  left join authors a on ba.author_id = a.id
  where
    regexp_replace(b.isbn13, '[^0-9]', '', 'g') = clean_isbn
    or regexp_replace(b.isbn10, '[^0-9]', '', 'g') = clean_isbn
  group by b.id
  limit 1;
end;
$$ language plpgsql;

-- Author search function
create or replace function search_authors(
  search_query text,
  max_results integer default 20
)
returns table (
  author_id text,
  author_name text,
  book_count bigint,
  relevance_score float
) as $$
begin
  return query
  with author_matches as (
    select
      a.id as author_id,
      a.name as author_name,
      count(distinct ba.book_id) as book_count,
      case
        when lower(a.name) = lower(search_query) then 1.0
        when lower(a.name) like lower(search_query) || '%' then 0.9
        when a.search_vector @@ plainto_tsquery('english', search_query) then
          ts_rank(a.search_vector, plainto_tsquery('english', search_query))::float
        else similarity(lower(a.name), lower(search_query)) * 0.7
      end as relevance_score
    from authors a
    left join book_authors_join ba on a.id = ba.author_id
    where
      lower(a.name) like '%' || lower(search_query) || '%'
      or a.search_vector @@ plainto_tsquery('english', search_query)
      or lower(a.name) % lower(search_query)
    group by a.id, a.name, a.search_vector
  )
  select * from author_matches
  order by relevance_score desc, book_count desc
  limit max_results;
end;
$$ language plpgsql;

-- Comments for search components
comment on materialized view book_search_view is 'Denormalized view optimized for full-text and fuzzy search';
comment on function search_books is 'Smart search combining exact, full-text, and fuzzy matching strategies';
comment on function search_by_isbn is 'Search for books by ISBN-10 or ISBN-13, handles various formats';
comment on function search_authors is 'Search for authors with relevance ranking and book count';
comment on function refresh_book_search_view is 'Refresh the search materialized view after bulk updates';

-- ============================================================================
-- SLUG MANAGEMENT
-- ============================================================================

-- Function to find book by slug or ID (supports legacy URLs)
create or replace function find_book_by_slug_or_id(identifier text)
returns table (
  book_id uuid,
  title text,
  subtitle text,
  slug text,
  authors text,
  isbn13 text,
  isbn10 text,
  s3_image_path text,
  published_date date,
  publisher text
) as $$
begin
  -- First try to find by slug
  return query
  select
    b.id as book_id,
    b.title,
    b.subtitle,
    b.slug,
    string_agg(a.name, ', ' order by ba.position) as authors,
    b.isbn13,
    b.isbn10,
    b.published_date,
    b.publisher
  from books b
  left join book_authors_join ba on b.id = ba.book_id
  left join authors a on ba.author_id = a.id
  where b.slug = identifier
  group by b.id
  limit 1;

  -- If not found, try as UUID (legacy support)
  if not found then
    return query
    select
      b.id as book_id,
      b.title,
      b.subtitle,
      b.slug,
      string_agg(a.name, ', ' order by ba.position) as authors,
      b.isbn13,
      b.isbn10,
      b.published_date,
      b.publisher
    from books b
    left join book_authors_join ba on b.id = ba.book_id
    left join authors a on ba.author_id = a.id
    where b.id::text = identifier
    group by b.id
    limit 1;
  end if;
end;
$$ language plpgsql;

-- Function to ensure slug uniqueness by appending counter if needed
create or replace function ensure_unique_slug(base_slug text)
returns text as $$
declare
  final_slug text;
  counter integer := 1;
begin
  final_slug := base_slug;

  -- Check if slug exists
  while exists(select 1 from books where slug = final_slug) loop
    final_slug := base_slug || '-' || counter;
    counter := counter + 1;
  end loop;

  return final_slug;
end;
$$ language plpgsql;

comment on function find_book_by_slug_or_id is 'Find book by SEO slug or UUID, supports legacy URL patterns';
comment on function ensure_unique_slug is 'Generate unique slug by appending counter if base slug already exists';

-- ============================================================================
-- RECOMMENDATIONS CACHE
-- ============================================================================

-- Cache for book-to-book recommendations
create table if not exists book_recommendations (
  id text primary key, -- NanoID (10 chars via IdGenerator.generate())
  source_book_id uuid not null references books(id) on delete cascade,
  recommended_book_id uuid not null references books(id) on delete cascade,
  source text not null, -- 'GOOGLE_SIMILAR', 'SAME_AUTHOR', 'SAME_CATEGORY', 'AI_GENERATED'
  score float check (score >= 0 and score <= 1), -- Relevance score 0.0-1.0
  reason text, -- Why this was recommended
  generated_at timestamptz not null default now(),
  expires_at timestamptz default (now() + interval '30 days'),
  created_at timestamptz not null default now(),
  unique(source_book_id, recommended_book_id, source)
);

create index if not exists idx_book_recommendations_source on book_recommendations(source_book_id);
create index if not exists idx_book_recommendations_target on book_recommendations(recommended_book_id);
create index if not exists idx_book_recommendations_expires on book_recommendations(expires_at) where expires_at is not null;

comment on table book_recommendations is 'Cached book-to-book recommendations from various sources';
comment on column book_recommendations.source is 'Origin of recommendation: GOOGLE_SIMILAR, SAME_AUTHOR, SAME_CATEGORY, AI_GENERATED';
comment on column book_recommendations.score is 'Relevance score from 0.0 (weak) to 1.0 (strong)';
comment on column book_recommendations.expires_at is 'When to refresh this recommendation';

-- ============================================================================
-- IMAGE METADATA EXTENSION
-- ============================================================================

-- Add metadata columns to book_image_links for completeness
alter table book_image_links
add column if not exists width integer,
add column if not exists height integer,
add column if not exists file_size_bytes integer,
add column if not exists is_high_resolution boolean,
add column if not exists s3_image_path text,
add column if not exists s3_uploaded_at timestamptz,
add column if not exists download_error text;

comment on column book_image_links.width is 'Image width in pixels';
comment on column book_image_links.height is 'Image height in pixels';
comment on column book_image_links.file_size_bytes is 'File size in bytes';
comment on column book_image_links.is_high_resolution is 'True if image is high quality (>300px width or >100KB)';
comment on column book_image_links.s3_image_path is 'S3 path to our persisted copy of this image';
comment on column book_image_links.s3_uploaded_at is 'When we uploaded this image to S3';
comment on column book_image_links.download_error is 'Error message if download failed';

-- ============================================================================
-- MIGRATION HELPERS
-- ============================================================================

-- PostgreSQL function to generate slug from title and authors
-- Used during migration when Java SlugGenerator is not available
create or replace function generate_slug(title text, author_name text default null)
returns text as $$
declare
  slug text;
begin
  -- Start with title
  slug := lower(title);

  -- Basic replacements
  slug := regexp_replace(slug, '&', 'and', 'g');

  -- Remove accents/diacritics
  slug := translate(slug,
    'àáäâãåèéëêìíïîòóöôõùúüûñçğışÀÁÄÂÃÅÈÉËÊÌÍÏÎÒÓÖÔÕÙÚÜÛÑÇĞİŞ',
    'aaaaaaeeeeiiiiooooouuuuncgisAAAAAEEEEIIIIOOOOOUUUUNCGIS');

  -- Keep only alphanumeric and spaces/hyphens
  slug := regexp_replace(slug, '[^a-z0-9\s-]', '', 'g');

  -- Replace spaces with hyphens
  slug := regexp_replace(slug, '[\s_]+', '-', 'g');

  -- Remove multiple consecutive hyphens
  slug := regexp_replace(slug, '-+', '-', 'g');

  -- Trim hyphens from start/end
  slug := trim(both '-' from slug);

  -- Truncate title part to 60 chars at word boundary
  if length(slug) > 60 then
    slug := substring(slug from 1 for 60);
    -- Try to cut at last hyphen
    slug := regexp_replace(slug, '-[^-]*$', '');
  end if;

  -- Add author if provided
  if author_name is not null and author_name != '' then
    declare
      author_slug text;
    begin
      author_slug := lower(author_name);
      author_slug := regexp_replace(author_slug, '[^a-z0-9\s-]', '', 'g');
      author_slug := regexp_replace(author_slug, '[\s_]+', '-', 'g');
      author_slug := regexp_replace(author_slug, '-+', '-', 'g');
      author_slug := trim(both '-' from author_slug);

      -- Truncate author to 30 chars
      if length(author_slug) > 30 then
        author_slug := substring(author_slug from 1 for 30);
        author_slug := regexp_replace(author_slug, '-[^-]*$', '');
      end if;

      slug := slug || '-' || author_slug;
    end;
  end if;

  -- Final truncation to 100 chars
  if length(slug) > 100 then
    slug := substring(slug from 1 for 100);
    slug := regexp_replace(slug, '-[^-]*$', '');
  end if;

  -- Ensure it's not empty
  if slug = '' or slug is null then
    slug := 'book';
  end if;

  return slug;
end;
$$ language plpgsql;

-- Function to batch generate slugs for existing books
-- Call this after migration to populate slugs
create or replace function generate_all_book_slugs()
returns void as $$
declare
  book_record record;
  base_slug text;
  final_slug text;
  counter integer;
begin
  -- Loop through all books without slugs
  for book_record in
    select
      b.id,
      b.title,
      string_agg(a.name, ' ' order by ba.position) as first_author
    from books b
    left join book_authors_join ba on b.id = ba.book_id and ba.position = 0
    left join authors a on ba.author_id = a.id
    where b.slug is null or b.slug = ''
    group by b.id, b.title
  loop
    -- Generate base slug
    base_slug := generate_slug(book_record.title, book_record.first_author);
    final_slug := base_slug;
    counter := 1;

    -- Ensure uniqueness
    while exists(select 1 from books where slug = final_slug and id != book_record.id) loop
      counter := counter + 1;
      final_slug := base_slug || '-' || counter;
    end loop;

    -- Update the book with its slug
    update books set slug = final_slug where id = book_record.id;
  end loop;

  raise notice 'Generated slugs for all books';
end;
$$ language plpgsql;

comment on function generate_slug is 'Generate URL slug from title and optional author, used during migration';
comment on function generate_all_book_slugs is 'Batch generate slugs for all books that dont have one, used after data migration';
